{"cells":[{"cell_type":"markdown","source":["https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n\nCompetition Description:\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n\nPractice Skills:\n\nCreative feature engineering Advanced regression techniques like random forest and gradient boosting"],"metadata":{}},{"cell_type":"markdown","source":["download data sets from the Kaggle and import csv files"],"metadata":{}},{"cell_type":"code","source":["%fs ls dbfs:/FileStore/tables/iz4qo8a01498148128281/"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["%python\n\ntrain = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('dbfs:/FileStore/tables/iz4qo8a01498148128281/train.csv')\ntest = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('dbfs:/FileStore/tables/iz4qo8a01498148128281/test.csv')\n\ndisplay(train)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["train.registerTempTable(\"train\")\ntest.registerTempTable(\"test\")"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["%sql show tables"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["Checking the data formats for each columns"],"metadata":{}},{"cell_type":"code","source":["train.printSchema()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["print(train.count())\nprint(test.count())"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["%python\nlist(train)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Data transformation, merging tables, and cleaning"],"metadata":{}},{"cell_type":"code","source":["%scala\nval train = sqlContext.table(\"train\")\nval test = sqlContext.table(\"test\")"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["%scala\nsqlContext.cacheTable(\"train\")\nsqlContext.cacheTable(\"test\")"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["Converting categorical variables from string to numeric forms."],"metadata":{}},{"cell_type":"code","source":["%scala\nimport org.apache.spark.ml.feature.StringIndexer \n\nval val1 = new StringIndexer().setInputCol(\"MSZoning\").setOutputCol(\"MSZoning1\") \nval val2 = new StringIndexer().setInputCol(\"Neighborhood\").setOutputCol(\"Neighborhood1\") \nval val3 = new StringIndexer().setInputCol(\"LotShape\").setOutputCol(\"LotShape1\") \nval val4 = new StringIndexer().setInputCol(\"LandContour\").setOutputCol(\"LandContour1\")\nval val5 = new StringIndexer().setInputCol(\"LandSlope\").setOutputCol(\"LandSlope1\") \nval val6 = new StringIndexer().setInputCol(\"PavedDrive\").setOutputCol(\"PavedDrive1\")\nval val7 = new StringIndexer().setInputCol(\"Condition2\").setOutputCol(\"Condition21\") \nval val8 = new StringIndexer().setInputCol(\"ExterCond\").setOutputCol(\"ExterCond1\")\nval val9 = new StringIndexer().setInputCol(\"BsmtQual\").setOutputCol(\"BsmtQual1\") \nval val10 = new StringIndexer().setInputCol(\"KitchenQual\").setOutputCol(\"KitchenQual1\")\nval val11 = new StringIndexer().setInputCol(\"RoofMatl\").setOutputCol(\"RoofMatl1\") \nval val12 = new StringIndexer().setInputCol(\"CentralAir\").setOutputCol(\"CentralAir1\")\nval val13 = new StringIndexer().setInputCol(\"Functional\").setOutputCol(\"Functional1\")\nval val14 = new StringIndexer().setInputCol(\"FireplaceQu\").setOutputCol(\"FireplaceQu1\")\nval val15 = new StringIndexer().setInputCol(\"GarageType\").setOutputCol(\"GarageType1\") \nval val16 = new StringIndexer().setInputCol(\"GarageFinish\").setOutputCol(\"GarageFinish1\")\nval val17 = new StringIndexer().setInputCol(\"GarageQual\").setOutputCol(\"GarageQual1\") \nval val18 = new StringIndexer().setInputCol(\"GarageCond\").setOutputCol(\"GarageCond1\")\nval val19 = new StringIndexer().setInputCol(\"SaleCondition\").setOutputCol(\"SaleCondition1\") \n\nval train1 = val1.fit(train).transform(train)\nval train2 = val2.fit(train1).transform(train1)\nval train3 = val3.fit(train2).transform(train2)\nval train4 = val4.fit(train3).transform(train3)\nval train5 = val5.fit(train4).transform(train4)\nval train6 = val6.fit(train5).transform(train5)\nval train7 = val7.fit(train6).transform(train6)\nval train8 = val8.fit(train7).transform(train7)\nval train9 = val9.fit(train8).transform(train8)\nval train10 = val10.fit(train9).transform(train9)\nval train11 = val11.fit(train10).transform(train10)\nval train12 = val12.fit(train11).transform(train11)\nval train13 = val13.fit(train12).transform(train12)\nval train14 = val14.fit(train13).transform(train13)\nval train15 = val15.fit(train14).transform(train14)\nval train16 = val16.fit(train15).transform(train15)\nval train17 = val17.fit(train16).transform(train16)\nval train18 = val18.fit(train17).transform(train17)\nval train19 = val19.fit(train18).transform(train18)\n\n\n\n\n// indexed.show()\n// indexed.printSchema()\ndisplay(train19)\ntrain19.registerTempTable(\"trainCat\")\n\n// Qurious how the 'MSZoning' values below are not numerical but still showing the string values."],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["%sql show tables"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["%sql SELECT * FROM traincat limit 30\n"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["%sql\nshow columns from traincat"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["Creating a new table with variabels that are selected from a preliminary variable selection step.  The preliminary variable selection step is not included here."],"metadata":{}},{"cell_type":"code","source":["%sql\ndrop table if exists cleaned_train;\n\ncreate table cleaned_train as\nselect MSZoning1, Neighborhood1,  \nLotShape1, LandContour1, LandSlope1, PavedDrive1,\nCondition21, ExterCond1, BsmtQual1, KitchenQual1,\nRoofMatl1, CentralAir1, FireplaceQu1,\nGarageType1, GarageFinish1,  GarageQual1, GarageCond1,\nSaleCondition1, Functional1,\n-- # Numerical below\nMSSubClass, LotFrontage, LotArea, OverallQual, OverallCond, \nBsmtFinSF1, BsmtFinSF2, BsmtUnfSF, 1stFlrSF, 2ndFlrSF, GrLivArea,\nBsmtFullBath, BsmtHalfBath, FullBath, HalfBath, BedroomAbvGr, KitchenAbvGr, Fireplaces,\nGarageCars, GarageArea, WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, \nPoolArea, YrSold, YearBuilt, YearRemodAdd, MoSold, SalePrice\nfrom traincat"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["%sql show tables"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["%scala\nval cleaned_train = sqlContext.table(\"cleaned_train\")\ndisplay(cleaned_train.describe())"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["Trials to remove NA values from 'MasVnrArea' column"],"metadata":{}},{"cell_type":"code","source":["%scala\nval cleaned_train2 = cleaned_train.na.fill(0)\ncleaned_train2.registerTempTable(\"cleaned_train2\")\ndisplay(cleaned_train2.describe())"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["%r # could not replace the NAs from MasVnrArea and this r fnc fails also\ncleaned_train2[is.na(cleaned_train2)] <- 0"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["NA removing tentative solution:  'MasVnrArea' variable is not selected from the above table 'cleaned_train'"],"metadata":{}},{"cell_type":"markdown","source":["We're going to have to put all of it into one column of a vector type for Spark MLLib. \n\nThis makes it easy to embed a prediction right in a DataFrame and also makes it very clear as to what is getting passed into the model and what isn't without have to convert it to a numpy array or specify an R formula. \n\nThis also makes it easy to incrementally add new features, simply by adding to the vector. \n\nIn the below case rather than specifically adding them in, I'm going to create a exclusionary group and just remove what is NOT a feature."],"metadata":{}},{"cell_type":"code","source":["%scala\nval nonFeatureCols = Array(\"SalePrice\")\nval featureCols = cleaned_train2.columns.diff(nonFeatureCols)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["%scala\ncleaned_train2.printSchema()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["Now I'm going to use the VectorAssembler in Apache Spark to Assemble all of these columns into one single vector. To do this I'll have to set the input columns and output column. Then I'll use that assembler to transform the prepped data to my final dataset."],"metadata":{}},{"cell_type":"code","source":["%scala \nimport org.apache.spark.ml.feature.VectorAssembler\n\nval assembler = new VectorAssembler()\n  .setInputCols(featureCols)\n  .setOutputCol(\"features\")\nval finalPrep = assembler.transform(cleaned_train2)\n\nval Array(training, testing) = finalPrep.randomSplit(Array(0.7, 0.3))\n\n// Going to cache the data to make sure things stay snappy!\ntraining.cache()\ntesting.cache()\n\nprintln(training.count())\nprintln(testing.count())"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["%scala display(finalPrep)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["%scala training.select(\"MSZoning1\").show()"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["Now we're going to get into the core of Apache Spark MLLib. At a high level, we're going to create an instance of a regressor or classifier, that in turn will then be trained and return a Model type. Whenever you access Spark MLLib you should be sure to import/train on the name of the algorithm you want as opposed to the Model type. "],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["%scala\n\nimport org.apache.spark.ml.regression.LinearRegression\n\nval lrModel = new LinearRegression()\n  .setLabelCol(\"SalePrice\")\n  .setFeaturesCol(\"features\")\n  .setElasticNetParam(0.5)\n\nprintln(\"Printing out the model Parameters:\")\nprintln(\"-\"*20)\nprintln(lrModel.explainParams)\nprintln(\"-\"*20)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["Now finally we can go about fitting our model! You'll see that we're going to do this in a series of steps. First we'll fit it, then we'll use it to make predictions via the transform method. This is the same way you would make predictions with your model in the future however in this case we're using it to evaluate how our model is doing. We'll be using regression metrics to get some idea of how our model is performing, we'll then print out those values to be able to evaluate how it performs."],"metadata":{}},{"cell_type":"code","source":["%scala \nimport org.apache.spark.mllib.evaluation.RegressionMetrics\nval lrFitted = lrModel.fit(training)"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":["Prediction vs SalePrice"],"metadata":{}},{"cell_type":"code","source":["%scala\nval holdout = lrFitted\n  .transform(testing)\n  .selectExpr(\"SalePrice as SalePrice\",\n  \"prediction as Prediction\")\ndisplay(holdout)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["%scala\nval rm = new RegressionMetrics(\n  holdout.select(\"Prediction\", \"SalePrice\").rdd.map(x =>\n  (x(0).asInstanceOf[Double], x(1).asInstanceOf[Double])))\n\nprintln(\"MSE: \" + rm.meanSquaredError)\nprintln(\"MAE: \" + rm.meanAbsoluteError)\nprintln(\"RMSE Squared: \" + rm.rootMeanSquaredError)\nprintln(\"R Squared: \" + rm.r2)\nprintln(\"Explained Variance: \" + rm.explainedVariance + \"\\n\")"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["2nd method"],"metadata":{}},{"cell_type":"code","source":["%scala\nimport org.apache.spark.ml.regression.RandomForestRegressor\nimport org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}\n\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\n\nimport org.apache.spark.ml.{Pipeline, PipelineStage}\n\nval rfModel = new RandomForestRegressor()\n  .setLabelCol(\"SalePrice\")\n  .setFeaturesCol(\"features\")\n\nval paramGrid = new ParamGridBuilder()\n  .addGrid(rfModel.maxDepth, Array(5, 10))\n  .addGrid(rfModel.numTrees, Array(20, 60))\n  .build()\n// Note, that this parameter grid will take a long time\n// to run in the community edition due to limited number\n// of workers available! Be patient for it to run!\n// If you want it to run faster, remove some of\n// the above parameters and it'll speed right up!\n\nval steps:Array[PipelineStage] = Array(rfModel)\n\nval pipeline = new Pipeline().setStages(steps)\n\nval cv = new CrossValidator() // you can feel free to change the number of folds used in cross validation as well\n  .setEstimator(pipeline) // the estimator can also just be an individual model rather than a pipeline\n  .setEstimatorParamMaps(paramGrid)\n  .setEvaluator(new RegressionEvaluator().setLabelCol(\"SalePrice\"))\n\nval pipelineFitted = cv.fit(training)"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":["Now we've trained our model! Let's take a look at which version performed best!"],"metadata":{}},{"cell_type":"code","source":["%scala\nprintln(\"The Best Parameters:\\n--------------------\")\nprintln(pipelineFitted.bestModel.asInstanceOf[org.apache.spark.ml.PipelineModel].stages(0))\npipelineFitted\n  .bestModel.asInstanceOf[org.apache.spark.ml.PipelineModel]\n  .stages(0)\n  .extractParamMap"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["%scala\nval holdout2 = pipelineFitted.bestModel\n  .transform(testing)\n  .selectExpr(\"SalePrice as SalePrice\",\n  \"prediction as Prediction\")\ndisplay(holdout2)"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":47}],"metadata":{"name":"HomeSalePrice","notebookId":980512136643183},"nbformat":4,"nbformat_minor":0}
