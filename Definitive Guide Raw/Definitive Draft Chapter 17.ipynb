{"cells":[{"cell_type":"code","source":["%scala\nval bInput = spark.read.load(\"/FileStore/tables/abvt587l1497651362610/part_r_00000_e02e56d5_d522_4b93_a7f2_f2dc1b2fdba9_gz-8fdf6.parquet\")\n.selectExpr(\"features\", \"cast(label as double) as label\")"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["bInput = spark.read.load(\"/FileStore/tables/abvt587l1497651362610/part_r_00000_e02e56d5_d522_4b93_a7f2_f2dc1b2fdba9_gz-8fdf6.parquet\")\\\n.selectExpr(\"features\", \"cast(label as double) as label\")"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["%scala\nimport org.apache.spark.ml.classification.LogisticRegression\nval lr = new LogisticRegression()\nvar lrModel = lr.fit(bInput)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression()\nlrModel = lr.fit(bInput)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["lrModel.coefficients\nlrModel.intercept"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["%scala\nimport org.apache.spark.ml.classification.BinaryLogisticRegressionSummary\nval summary = lrModel.summary\nval bSummary = summary\n.asInstanceOf[BinaryLogisticRegressionSummary]\nbSummary.areaUnderROC\nbSummary.roc\nbSummary.pr.show()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["summary = lrModel.summary\nsummary.areaUnderROC\nsummary.roc\nsummary.pr.show()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["summary.objectiveHistory"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["%scala\nimport org.apache.spark.ml.classification.DecisionTreeClassifier\nval dt = new DecisionTreeClassifier()\nval dtModel = dt.fit(bInput)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndtModel = dt.fit(bInput)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["%scala\nimport org.apache.spark.ml.classification.RandomForestClassifier\nval model = new RandomForestClassifier()\nval trainedModel = dt.fit(bInput)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["%scala\nimport org.apache.spark.ml.classification.GBTClassifier\nval model = new GBTClassifier()\nval trainedModel = dt.fit(bInput)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\nmodel = RandomForestClassifier()\ntrainedModel = dt.fit(bInput)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["from pyspark.ml.classification import GBTClassifier\nmodel = GBTClassifier()\ntrainedModel = dt.fit(bInput)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["%scala\nimport org.apache.spark.ml.classification.MultilayerPerceptronClassifier\nval model = new MultilayerPerceptronClassifier()\nval trainedModel = dt.fit(bInput)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["from pyspark.ml.classification import MultilayerPerceptronClassifier\nmodel = MultilayerPerceptronClassifier()\ntrainedModel = dt.fit(bInput)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["%scala\nimport org.apache.spark.ml.classification.NaiveBayes\nval model = new NaiveBayes()\nval trainedModel = dt.fit(bInput)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["from pyspark.ml.classification import NaiveBayes\nmodel = NaiveBayes()\ntrainedModel = dt.fit(bInput)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["%scala\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["%scala\nimport org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\nval out = lrModel.transform(bInput)\n.select(\"prediction\", \"label\")\n.rdd\n.map(x => (x(0).asInstanceOf[Double], x(1).asInstanceOf[Double]))\nval metrics = new BinaryClassificationMetrics(out)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["from pyspark.mllib.evaluation import BinaryClassificationMetrics\nout = lrModel.transform(bInput)\\\n.select(\"prediction\", \"label\")\\\n.rdd\\\n.map(lambda x: (float(x[0]), float(x[1])))\nmetrics = BinaryClassificationMetrics(out)\nmetrics.pr.toDF().show()\nmetrics.areaUnderROC"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":23}],"metadata":{"name":"Definitive Draft Chapter 17","notebookId":2060825016293887},"nbformat":4,"nbformat_minor":0}
