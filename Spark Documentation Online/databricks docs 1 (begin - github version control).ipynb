{"cells":[{"cell_type":"code","source":["# A Spark Context is already created for you.\n# Do not create another or unspecified behavior may occur.\nspark\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# A SQLContext is also already created for you.\n# Do not create another or unspecified behavior may occur.\n# As you can see below, the sqlContext provided is a HiveContext.\nsqlContext\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# A Spark Context is already created for you.\n# Do not create another or unspecified behavior may occur.\nsc\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["1+1 # => 2\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["myDataFrame = sc.parallelize([('a', 1), ('b', 2), ('c', 3)]).toDF()\ndisplay(myDataFrame)\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["dbutils.fs.mkdirs(\"dbfs:/databricks/init/\")\n"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["display(dbutils.fs.ls(\"dbfs:/databricks/init/\"))\n"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["dbutils.fs.mkdirs(\"dbfs:/databricks/init/PostgreSQL/\")\n"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["dbutils.fs.put(\"/databricks/init/PostgreSQL/postgresql-install.sh\",\"\"\"\n#!/bin/bash\nwget --quiet -O /mnt/driver-daemon/jars/postgresql-9.3-1101-jdbc4.jar http://central.maven.org/maven2/org/postgresql/postgresql/9.3-1101-jdbc4/postgresql-9.3-1101-jdbc4.jar\nwget --quiet -O /mnt/jars/driver-daemon/postgresql-9.3-1101-jdbc4.jar http://central.maven.org/maven2/org/postgresql/postgresql/9.3-1101-jdbc4/postgresql-9.3-1101-jdbc4.jar\n\"\"\", True)\n"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["display(dbutils.fs.ls(\"dbfs:/databricks/init/PostgreSQL/postgresql-install.sh\"))\n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["clusterName = \"YOUR_CLUSTER_NAME\"\n"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["dbutils.fs.put(\"dbfs:/databricks/init/my-echo.sh\" ,\"\"\"\n#!/bin/bash\n\necho \"hello\" >> /hello.txt\n\"\"\", True)\n"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["display(dbutils.fs.ls(\"dbfs:/databricks/init/\"))\n"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["dbutils.fs.rm(\"/databricks/init/my-echo.sh\")\n"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["dbutils.fs.rm(\"dbfs:/databricks/init/PostgreSQL/postgresql-install.sh\")\n"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["curl https://YOUR_HOSTNAME/sql/protocolv1/o/0/YOUR_CLUSTER_ID -H \"Authorization: Basic $(echo -n 'YOUR_USERNAME:YOUR_PASSWORD' | base64)\"\n"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["import sys\nprint(sys.version)\n"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["%sh python --version\n"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["# Hello This is a Title"],"metadata":{}},{"cell_type":"code","source":["%sql SELECT 1\n"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["x = 5\n"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["print(x) # => 5\n"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["displayHTML(\"\"\"<font size=\"5\" color=\"blue\">Bike Sharing Data Analysis Dashboard</font>\"\"\")"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["We can also create a label using Markdown."],"metadata":{}},{"cell_type":"code","source":["df = sqlContext.read.format(\"com.databricks.spark.csv\")\\\n  .load(\"dbfs:/databricks-datasets/bikeSharing/data-001/day.csv\", header=True)\n\ndf.registerTempTable(\"bikeshare\")\n\ndisplay(sqlContext.sql(\"SELECT season, MAX(temp) as temperature, MAX(hum) as humidity, MAX(windspeed) as windspeed FROM bikeshare GROUP BY season Order By season\"))"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["%sql SELECT season, MAX(temp) as temperature, MAX(hum) as humidity, MAX(windspeed) as windspeed FROM bikeshare GROUP BY season Order By season"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["%sql SELECT mnth as month, AVG(temp) as temperature, AVG(hum) as humidity, AVG(windspeed) as windspeed FROM bikeshare GROUP BY mnth Order by month * 1 ASC"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["%sql SELECT mnth as month, MAX(temp) as max_temperature, MAX(hum) as max_humidity, MAX(windspeed) as max_windspeed FROM bikeshare GROUP BY mnth Order by mnth * 1 ASC"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["%sql SELECT mnth as month, MIN(temp) as max_temperature, MIN(hum) as max_humidity, MIN(windspeed) as max_windspeed FROM bikeshare GROUP BY mnth Order by mnth * 1 ASC"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":31}],"metadata":{"name":"databricks docs 1 (begin - github version control)","notebookId":3145651491070640},"nbformat":4,"nbformat_minor":0}
