{"cells":[{"cell_type":"markdown","source":["In this exercise we will use Spark to explore the hypothesis stated below:\n\n**The number of farmer's markets in a given zip code can be predicted from the income and taxes paid in a given area.**\n\nWe explore the process for discovering whether or not we can accurately predict the number of farmer's markets.  We will use two datasets.\n\n![img](http://training.databricks.com/databricks_guide/USDA_logo.png)\n\nThe [**Farmers Markets Directory and Geographic Data**](http://catalog.data.gov/dataset/farmers-markets-geographic-data/resource/cca1cc8a-9670-4a27-a8c7-0c0180459bef) dataset contains information on the longitude and latitude, state, address, name, and zip code of Farmers Markets in the United States. The raw data is published by the Department of Agriculture. \n\n![img](http://training.databricks.com/databricks_guide/irs-logo.jpg)\n\nThe [**SOI Tax Stats - Individual Income Tax Statistics - ZIP Code Data (SOI)**](http://catalog.data.gov/dataset/zip-code-data) study provides detailed tabulations of individual income tax return data at the state and ZIP code level and is provided by the IRS. The data includes items, such as:\n\n- Number of returns, which approximates the number of households\n- Number of personal exemptions, which approximates the population\n- Adjusted gross income\n- Wages and salaries\n- Dividends before exclusion\n- Interest received"],"metadata":{}},{"cell_type":"markdown","source":["Read in the data\n\nThis data is located in in csv files and Apache Spark 2.0 can read the data in directly."],"metadata":{}},{"cell_type":"code","source":["taxes2013 = spark.read\\\n  .option(\"header\", \"true\")\\\n  .csv(\"dbfs:/databricks-datasets/data.gov/irs_zip_code_data/data-001/2013_soi_zipcode_agi.csv\")"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["markets = spark.read\\\n  .option(\"header\", \"true\")\\\n  .csv(\"dbfs:/databricks-datasets/data.gov/farmers_markets_geographic_data/data-001/market_data.csv\")"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["Use the `display` command to take a quick look at the dataframes you created."],"metadata":{}},{"cell_type":"code","source":["display(taxes2013)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["Now register the DataFrames as Spark SQL tables so that we can use our SQL skills to manipulate the data. The lifetime of this temporary table is tied to the Spark Context that was used to create this DataFrame. When you shutdown the SQLContext associated with a cluster the temporary table disappears as well."],"metadata":{}},{"cell_type":"code","source":["taxes2013.createOrReplaceTempView(\"taxes2013\")\nmarkets.createOrReplaceTempView(\"markets\")"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["## Running SQL Commands\n\nThis is a python notebook.  To use another language in a python notebook we prefix the cell with the language identifier.  To use SQL in your python notebook, prefix the cell with `%sql`\n\nUse SQL to `show tables`."],"metadata":{}},{"cell_type":"code","source":["%sql show tables"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Take a quick look at the tables using `SELECT *`.  This is very similar to calling `display` on the DataFrame."],"metadata":{}},{"cell_type":"code","source":["%sql SELECT * FROM taxes2013"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["Next, cleanup the data using SQL\n1. Create a new table called `cleaned_taxes` from the `taxes2013` temp table\n1. All the values are currently strings, convert them to approriate data types as needed\n  1. zipcode => int\n  1. mars1 => int\n  1. mars2 => int\n  1. numdep => int\n  1. A02650 => double\n  1. A00300 => double\n  1. a01000 => double\n  1. a00900 => double \n1. Rename columns for clarity as needed\n  1. state => state\n  1. zipcode => zipcode\n  1. mars1 => single_returns\n  1. mars2 => joint_returns\n  1. numdep => numdep\n  1. A02650 => total_income_amount\n  1. A00300 => taxable_interest_amount\n  1. a01000 => net_capital_gains\n  1. a00900 => biz_net_income\n1. Shorten each zip code to 4 digits instead of 5, to group nearby areas together"],"metadata":{}},{"cell_type":"code","source":["%sql\nDROP TABLE IF EXISTS cleaned_taxes;\n\nCREATE TABLE cleaned_taxes AS\nSELECT \n  state, \n  int(zipcode / 10) as zipcode,\n  int(mars1) as single_returns,\n  int(mars2) as joint_returns,\n  int(numdep) as numdep,\n  double(A02650) as total_income_amount,\n  double(A00300) as taxable_interest_amount,\n  double(a01000) as net_capital_gains,\n  double(a00900) as biz_net_income\nFROM taxes2013"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["Now that the data is cleaned up, create some nice plots\n\nExplore the average total income per zip code per state. \n\nWhich states have the highest income per zip code?"],"metadata":{}},{"cell_type":"code","source":["%sql SELECT state, total_income_amount FROM cleaned_taxes "],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["New Jersey and California have higher average incomes per zip code."],"metadata":{}},{"cell_type":"markdown","source":["Next let's explore some specifics of this particular dataset.\n\nUse SQL to `describe` the dataset so that you can see the schema."],"metadata":{}},{"cell_type":"code","source":["%sql describe cleaned_taxes"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["Let's look at the set of zip codes with the lowest total capital gains and plot the results."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT zipcode, SUM(net_capital_gains) AS cap_gains\nFROM cleaned_taxes\n  WHERE NOT (zipcode = 0000 OR zipcode = 9999)\nGROUP BY zipcode\nORDER BY cap_gains ASC\nLIMIT 10"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["Let's look at a combination of capital gains and business net income to see what we find. \n\nBuild a `combo` metric that represents the total capital gains and business net income by zip code."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT zipcode,\n  SUM(biz_net_income) as business_net_income,\n  SUM(net_capital_gains) as capital_gains,\n  SUM(net_capital_gains) + SUM(biz_net_income) as capital_and_business_income\nFROM cleaned_taxes\n  WHERE NOT (zipcode = 0000 OR zipcode = 9999)\nGROUP BY zipcode\nORDER BY capital_and_business_income DESC\nLIMIT 50"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["We can also get a peek at what will happen when we execute the query.\n\nUse the `EXPLAIN` keyword in SQL."],"metadata":{}},{"cell_type":"code","source":["%sql\nEXPLAIN\n  SELECT zipcode,\n    SUM(biz_net_income) as net_income,\n    SUM(net_capital_gains) as cap_gains,\n    SUM(net_capital_gains) + SUM(biz_net_income) as combo\n  FROM cleaned_taxes\n  WHERE NOT (zipcode = 0000 OR zipcode = 9999)\n  GROUP BY zipcode\n  ORDER BY combo desc\n  limit 50"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["We can see above that we're fetching the data from `dbfs:/user/hive/warehouse/cleaned_taxes` which is where the data is stored when we registered it as a temporary table. \n\nLet's `cache` the data"],"metadata":{}},{"cell_type":"code","source":["%sql CACHE TABLE cleaned_taxes"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["When we cache data using SQL, Spark caches *eagerly*--right away.  This differs from `cacheTable` on the `SqlContext` which caches the data only when it is needed.\n\nLet's run the exact same query again. You'll notice that it takes just a fraction of the time because the data is stored in memory."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT zipcode,\n  SUM(biz_net_income) as net_income,\n  SUM(net_capital_gains) as cap_gains,\n  SUM(net_capital_gains) + SUM(biz_net_income) as combo\nFROM cleaned_taxes\n  WHERE NOT (zipcode = 0000 OR zipcode = 9999)\nGROUP BY zipcode\nORDER BY combo desc\nlimit 50"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["Now `EXPLAIN` the plan"],"metadata":{}},{"cell_type":"code","source":["%sql\nEXPLAIN\n  SELECT zipcode,\n    SUM(biz_net_income) as net_income,\n    SUM(net_capital_gains) as cap_gains,\n    SUM(net_capital_gains) + SUM(biz_net_income) as combo\n  FROM cleaned_taxes\n  WHERE NOT (zipcode = 0000 OR zipcode = 9999)\n  GROUP BY zipcode\n  ORDER BY combo desc\n  limit 50"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["Instead of going down to the source data it performs a `InMemoryColumnarTableScan`. This means that it has all of the information that it needs in memory.\n\nNow let's look at the Farmer's Market Data. \n\nStart with a total summation of farmer's markets per state."],"metadata":{}},{"cell_type":"code","source":["%sql SELECT State, COUNT(State) as Sum\n      FROM markets \n      GROUP BY State "],"metadata":{},"outputs":[],"execution_count":33}],"metadata":{"name":"6-SparkSQL","notebookId":3737261653513087},"nbformat":4,"nbformat_minor":0}
